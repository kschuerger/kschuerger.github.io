---
# title: "Beer Case Study"
# author: "Kati Schuerger, Will Sherman, Randy Kim"
# date: "6/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Beer Case Study 

## load libraries
```{r library, include=T, error=F, message=F, warning=F, results='hide'}
library(tidyverse)
library(ggthemes)
library(dplyr)
library(ggmap)
library(maps)
library(caret)
library(class)
library(ggplot2)
library(grid)
library(gridExtra)
library(tidyr)
library(usmap)
library(highcharter)
library(broom)
library(tidyverse)
library(plotly)
library(e1071)
library(RColorBrewer)

```

## import the data 
```{r}
breweries = read.csv(file.choose(), header = TRUE)
head(breweries, n = 5)

beers = read.csv(file.choose(), header = TRUE)
head(beers, n = 5)
```

#1. How many breweries are present in each state?
```{r, warning=F}
# check structure of breweries df
# str(breweries)

## edit the State column to remove the blank space
## also convert to factor 
breweries$State = as.factor(substr(breweries$State, 2, 3))

st_reg <- data.frame(State=state.abb, Region=state.region)
st_reg <- rbind(st_reg, data.frame(State="DC", Region="Northeast"))

breweries <- left_join(breweries,st_reg)

## confirm all rows have a Region
# breweries %>% filter(is.na(Region) == TRUE)

# Plot breweries by state & region
breweries %>% ggplot(aes(x=State, fill = State)) +
  geom_histogram(stat="count") +
  labs(title="Count of breweries per state sorted by region") +
  theme(legend.position="none", axis.text.x=element_text(angle=45,hjust=0.8)) +
  facet_wrap(~Region, scale="free")
```
The above graph shows the number of breweries per state (broken down by region for more compact viewing).

```{r}
# Breweries by state 
# BreweriesByState = data.frame(table(breweries$State))
# colnames(BreweriesByState) = c("State","Breweries")
# BreweriesByState 

# Breweries by state with region 
BreweriesByStateRegion = data.frame(table(breweries$State, breweries$Region))
colnames(BreweriesByStateRegion) = c("State","Region","Breweries")
BreweriesByStateRegion %>% filter(Breweries > 0)

```


## 2. Merge beer data with the breweries data. Print the first 6 observations and the last six observations to check the merged file. 
```{r}
# rename Brew_ID to match column name in beers (for merge)
breweries = breweries %>% rename(Brewery_id = Brew_ID)
head(breweries, n = 5)

# merge the data 
dfBrews = merge(breweries, beers, by = c("Brewery_id"), all = FALSE)
head(dfBrews, n = 6)
tail(dfBrews, n = 6)

# rename columns in merged data 
colnames(dfBrews) = c("Brewery_ID","Brewery_Name","City","State","Region","Beer_Name",
                       "Beer_ID","ABV","IBU","Style","Ounces")

```

Heat map of breweries by state 
```{r}
# create new df to play with for heat map 
dfBrews2 = dfBrews 

dfBrews2$StateName = state.name[match(dfBrews$State, state.abb)]
# head(dfBrews2, n = 5)

# count up the occurance of each state.
BrewMapData = count(dfBrews2, StateName)
# head(BrewMapData, n = 5)
  
colnames(BrewMapData)[2] = "breweries" # change "n" to "breweries"

# make new column region with lowercase state name 
BrewMapData$region <- tolower(BrewMapData$StateName)

# drop the StateName column (first column)
BrewMapData2 = BrewMapData[-1]
# head(BrewMapData2, n = 5)

# get the state info
states = map_data("state")
#  head(states, n = 5)

# merge the state info and the brew data 
map.df <- merge(states,BrewMapData2, by="region", all.x=T)
# head(map.df, n = 5)
  
map.df <- map.df[order(map.df$order),]

# create heat map 
ggplot(map.df, aes(x=long,y=lat,group=group))+
  geom_polygon(aes(fill = breweries))+
  geom_path()+ 
  scale_fill_gradientn(colors = brewer.pal(9,"Blues"), na.value="grey90")+
  ggtitle("Breweries by State")+
  coord_map()

```

## 3. Address the missing values in each column.
```{r}
# see nulls in merged data
sapply(dfBrews,function(x) sum(is.na(x)))

# show breakdown of % missing for each state
na_byState <- data.frame()
for(i in st_reg$State){
  na_byState[i,1]=length(which(grepl(i,dfBrews$State)))
  na_byState[i,2]=length(which(grepl(i,dfBrews$State) & is.na(dfBrews$IBU)))
}
names(na_byState) <- c("Beers_count","IBU_NAs_count")
na_byState %>% mutate(Percent_NA = round(IBU_NAs_count/Beers_count*100,digits=0))


### set seed
set.seed(7)

### impute values for ABV NAs 
dfBrews$ABV = ifelse(is.na(dfBrews$ABV),
                     round(sample((mean(dfBrews$ABV, na.rm = TRUE) - sd(dfBrews$ABV, na.rm = TRUE)):
                                    (mean(dfBrews$ABV, na.rm = TRUE) + sd(dfBrews$ABV, na.rm = TRUE)),
                                  size = sum(is.na(dfBrews$ABV)), replace = T), 0), dfBrews$ABV)

# columns that have null values 
colnames(dfBrews)[!complete.cases(t(dfBrews))]
```

```{r}
### impute values for IBU using Naive Bayes 
# created editable data set
combined_df <- dfBrews

# split data frame into IBU known and IBU unknown
ibu_known <- combined_df[which(!is.na(combined_df$IBU)),]
ibu_unknown <- combined_df[which(is.na(combined_df$IBU)),]

############# Visualizations ##################################
#correlation between numerical vectors - weak association
ibu_known %>% select_if(is.numeric) %>% cor() %>% corrplot::corrplot()

#visualizing strongest relationship between IBU and categorical values
plot_ly(ibu_known, x= ~reorder(Style,IBU), y= ~IBU) %>%
add_boxplot() %>%
layout(title="IBU by Beer Style")
#visual comparison with ABV and Style (same order as IBU-relationship)
plot_ly(ibu_known, x= ~reorder(Style,IBU), y= ~ABV) %>%
add_boxplot() %>%
layout(title="ABV by Beer Style\nordered by increasing IBU")

###############################################################
# Training nB for classifying IBU
model <- naiveBayes(IBU~., data=ibu_known)


######### external cross validation ###########################
### multiple iterations
iterations = 100
masterAcc = matrix(nrow = iterations)

for(j in 1:iterations){
  train <- ibu_known[sample(seq(1:length(ibu_known$IBU)),
                            round(.7*length(ibu_known$IBU))),]
  test <- ibu_known[-sample(seq(1:length(ibu_known$IBU)),
                            round(.7*length(ibu_known$IBU))),]
  
  pred <- predict(model, train)
  t1 <- table(factor(pred, union(pred, train$IBU)),
              factor(train$IBU, union(pred, train$IBU)))
  CM <- confusionMatrix(t1)
  masterAcc[j] = CM$overall[1]
}
colMeans(masterAcc) # average accuracy across the 150 iterations
var(masterAcc)[1] # measure of the variance across the 150 iterations

# CM

# Impute nB
imp <- predict(model, ibu_unknown)
ibu_unknown_nB <- ibu_unknown

for(i in 1:nrow(ibu_unknown_nB)){
  ibu_unknown_nB$IBU[i] <- imp[i]
}

# attaching the predictions for unknown to known IBUs 
combined_df_nB <- rbind(ibu_known,ibu_unknown_nB)
combined_df_nB <- combined_df_nB[order(combined_df_nB$Brewery_ID),]

head(combined_df_nB, n = 5)
```

## 4. Compute the median alcohol content and international bitterness unit for each state. Plot a bar chart to compare.
```{r, warning=F, message=F}
sapply(combined_df_nB,function(x) sum(is.na(x)))

BrewBeerABV = data.frame(combined_df_nB %>% group_by(State, Region) %>% summarise(ABV=median(ABV)))

BrewBeerABV %>% ggplot(mapping=aes(x=State,y=ABV,fill=State)) + geom_bar(stat="identity",width=0.3,position="dodge") +
  theme(legend.position="none",axis.text.x=element_text(angle=45,vjust=0.1))+
  ggtitle("Median ABV by State") + ylab("Median ABV") + xlab("State") + facet_wrap(~Region, scale = "free")


BrewBeerIBU = data.frame(combined_df_nB %>% group_by(State, Region) %>% summarise(IBU=median(IBU)))

BrewBeerIBU %>% ggplot(mapping=aes(x=State,y=IBU,fill=State)) + geom_bar(stat="identity",width=0.3,position="dodge") +
  theme(legend.position="none",axis.text.x=element_text(angle=45,vjust=0.1))+
  ggtitle("Median IBU by State") + ylab("Median IBU") + xlab("State") + facet_wrap(~Region, scale = "free")

```

## 5. Which state has the maximum alcoholic (ABV) beer? Which state has the most bitter (IBU) beer?
```{r}
combined_df_nB[which.max(combined_df_nB$ABV),]
#Colorado at 12.8%

combined_df_nB[which.max(combined_df_nB$IBU),]
#Oregon at 138
```
The state with the ABV is Colorado with a value of `r max(combined_df_nB$ABV)`. And the state with the highest IBU is Oregon with an ABV of `r max(combined_df_nB$IBU)`. Neither of these values came from the imputed data (i.e. they were not previously NA values).

## 6. Comment on the summary statistics and distribution of the ABV variable.
```{r}
# ABV quantiles for median ABV values 
quantile(BrewBeerABV$ABV)

# distribution of ABV 
ggplot(data = dfBrews) + 
  geom_histogram(mapping = aes(x = ABV), fill = "blue")
## ABV distribution is slightly right skewed 

# summary statistics for ABV 
summary(dfBrews$ABV)


# violin plot
## create new df for violin plot
combined_df_nB_2 = combined_df_nB
## create new "hold" column to put 1 value for violin plot to work
combined_df_nB_2$hold = 1
## check the data 
head(combined_df_nB_2)
## violin plot 
combined_df_nB_2 %>% ggplot(aes(x = hold, y = ABV)) + geom_violin(fill = "blue") + 
  xlab("All Beers ABV Distribution") +  ylab("") + scale_x_discrete(labels = NULL)

zeros <- sum(ifelse(combined_df_nB$ABV==0,1,0))
```
The ABV variable had `r zeros` imputed zeros. The error rate for this is `r round(zeros/length(combined_df_nB$ABV)*100,2)`%. Additionally, 75% of the ABV falls between 5% - 6.7%. A general note of interest is that Budweiser has an ABV of 5%.


## 7. Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot. Make your best judgment of a relationship and EXPLAIN your answer.
```{r}
################## BY STATE #########################
# IBU
quantile(BrewBeerIBU$IBU)

####### quick scatterplot ##########################
ggplot(data = combined_df_nB) +
  geom_point(mapping = aes(x = ABV, y = IBU), color = "blue")


# linear model fit 
lm_fit = lm(ABV ~ IBU, data = combined_df_nB)
combined_df_nB %>% ggplot(aes(x=ABV,y=IBU,color=State)) + 
  geom_point() +
  ggtitle("ABV vs IBU by State") +
  theme(legend.position = "none") +
  theme(legend.title = element_blank()) +
  geom_smooth(method="lm",se=FALSE,color="black",size=0.1)


####### relationship between ABV and IBU ####################
combined_df_nB %>% ggplot(aes(x=ABV, y=IBU, color=ABV)) + 
  geom_point() + 
  geom_smooth() + 
  labs(color="Ratio of ABV vs IBU") +
  ggtitle("ABV vs IBU")


```

## 7 continued
```{r}
########### ABV and IBU relationship by ALE / IPA #################

#check to be sure we aren't missing anything by looking for IPA
#check for 'India Pale Ale' instead of 'IPA'
sum(grepl("India Pale Ale",combined_df_nB$Style)) - sum(grepl("India Pale Ale",combined_df_nB$Style) & grepl("IPA", combined_df_nB$Style))

#isolate IPAs & non-IPA Ales / note beer-style as iapsType
ipas = filter(combined_df_nB, grepl("Ale|IPA",Style))
ipas = ipas %>% mutate(ipasType = ifelse(grepl("IPA",Style),"IPA","Ale"))

ipas %>% ggplot(aes(x=ABV *100, y= IBU, color=ipasType)) +
  geom_point(position='jitter') +
  geom_smooth() +
  ggtitle('ABV vs IBU') +
  labs(subtitle="Ale and IPAs")+
  xlab('ABV (%)') +
  theme(legend.title=element_blank())


quantile(combined_df_nB$IBU)

```
We can see that there is a positive correlation between IBU and ABV. We can see a big cluster around 5% ABV, and we predict that these are regular 12 ounces of beers which, according to NIAAA in the U.S., contain between 4-7% ABV, with the average being 5%. Anything above estimates to be malt liquor which averages to be 7% ABV.
It is worth noting that correlation does not equal causation.
Next, we decided to compare ABV and IBU by Ale and IPA. We can see that the majority of Ales have low ABV and IBU while the majority of IPAs have high ABV and IBU. Budweiser has average 5% ABV and 7 IBU; therefore, we may carefully suggest focusing on products with ABVs within range of 5.6 to 5.8% and IBUs of 19 to 64. This range might be more competitive in the existing market. 


## 8. Budweiser would also like to investigate the difference with respect to IBU and ABV between IPAs (India Pale Ales) and other types of Ale (any beer with “Ale” in its name other than IPA).  You decide to use KNN classification to investigate this relationship.  Provide statistical evidence one way or the other. You can of course assume your audience is comfortable with percentages … KNN is very easy to understand conceptually.

## In addition, while you have decided to use KNN to investigate this relationship (KNN is required) you may also feel free to supplement your response to this question with any other methods or techniques you have learned.  Creativity and alternative solutions are always encouraged.

```{r}
################################################################################

ipas = filter(combined_df_nB, grepl("Ale|IPA",Style))
ipas = ipas %>% mutate(ipasType = ifelse(grepl("IPA",Style),"IPA","Ale"))

set.seed(7)
splitPerc = 0.7

trainIndices = sample(1:dim(ipas)[1],round(splitPerc*dim(ipas)[1]))
train = ipas[trainIndices,]
test = ipas[-trainIndices,]
classifications = knn(train[,c(8,9)],test[,c(8,9)],as.factor(train$ipasType),prob=TRUE,k=5)

# str(train)

set.seed(7)
splitPerc = 0.7
iterations = 100
nums = 100
masterAcc = matrix(nrow = iterations, ncol = nums)

for (j in 1:iterations)
{
  accs = data.frame(accuracy = numeric(100), k=numeric(100))
  trainIndices = sample(1:dim(ipas)[1],round(splitPerc*dim(ipas)[1]))
  train = ipas[trainIndices,]
  test = ipas[-trainIndices,]
  for (i in 1:nums)
  {
    classifications = knn(train[,c(8,9)],test[,c(8,9)],as.factor(train$ipasType),prob=TRUE,k=i)
    CM = confusionMatrix(table(as.factor(test$ipasType),classifications))
    masterAcc[j,i] = CM$overall[1]
  }
}

CM
## masterAcc # removed from knit
meanAcc=colMeans(masterAcc)

# plot k-values v. average accuracy  
{plot(seq(1,nums,1), meanAcc,type="l", xlab = "Values for K", 
      ylab = "Average Accuracy")
abline(v=which.max(meanAcc),col="red",lwd=1)
abline(h=max(meanAcc),col="red",lwd=1)}

# best values for K and highest accuracy 
## which.max(meanAcc) # 38 is best value for K
## max(meanAcc) # 81.8% is highest accuracy 

# internal cross validation for knn
classifications = knn.cv(ipas[,c(8,9)], ipas$ipasType, prob = TRUE, k = 38)
CM <- confusionMatrix(table(classifications, as.factor(ipas$ipasType)))
CM
# Accuracy = 81.8% 
# Sensitivity = 85.4%
# Specificity = 75.7%

```
From external cross-validations, the optimal number of nearest neighbors is `r which.max(meanAcc)`. From this, we checked our accuracy, sensitivity, and specificity of predicting IPA versus non-IPA ales. The accuracy for predicting IPA with internal cross-validation based on ABV and IBU was found to be `r round(CM$overall[[1]],4)*100`%, the specificity was `r round(CM$byClass[[2]],4)*100`%, and the sensitivity was `r round(CM$byClass[[1]],4)*100`%.

## 9
```{r, warning=F}
## table(combined_df_nB$Style) #checking list of styles
sum(ifelse(combined_df_nB$Style=="",1,0)) #finding the unidentified styles

style_byState <- combined_df_nB %>% select(Style, ABV, IBU, State, Region)

#replacing empty strings with 'unknown'
style_byState$Style <- replace(style_byState$Style,
                               which(style_byState==""),
                               "Unknown")
## table(style_byState$Style) #checking update

#creating the dataframe for State-preferences
style_byState %>% group_by(State) %>%
  summarize(Style = names(which.max(table(Style))),
            ABV = mean(ABV), #could switch to median if needed
            IBU = mean(IBU))
#creating the summary for grpahing
summary_byState <- style_byState %>%
  group_by(State) %>%
  summarize(Style = names(which.max(table(Style))),
            ABV = median(ABV),
            IBU = median(IBU))
summary_byState <- summary_byState %>% dplyr::rename(state=State)

beer_colors <- c("#FFCCFF", "#CC6633", "#993300",
                 "#330000", "#FFCC66", "#663300",
                 "#006699", "#3399FF", "#99CCFF",
                 "#660066", "#66FF00", "#006600")

plot_usmap(regions="states",
           data=summary_byState,
           values="Style",labels=F,offset=0.5, color="white") +
  theme(legend.position="bottom",
        legend.title=element_blank()) +
  labs(title = "Preferred Beer Style\nby State") +
  scale_fill_manual(values=beer_colors)
```

The graphic here depicts majority preference by state for certain styles of beers. When ties occurred, we gave the win to the most prevalent beer-type nationally. The focus of our analysis here was to present a by-state retail option. With additional supply-chain information, we may be able to help optimize future distribution or optimization efforts.
